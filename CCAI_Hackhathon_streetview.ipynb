{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "E_SoJbVWo9Gn",
    "outputId": "d0d40187-f0a6-4048-8131-1789439b45fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "### Function that query the image from google street view API, save the image in drive and return the queried image\n",
    "import cv2\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def GetImage_fromAPI(address):\n",
    "  key = #<Your KEY!!>\n",
    "  base_url = \"https://maps.googleapis.com/maps/api/streetview?size=128x128&location=\"\n",
    "  parameter = \"&fov=105&pitch=25&source=outdoor&key=\"\n",
    "  \n",
    "  query_url = base_url+address+parameter+key\n",
    "  \n",
    "  r = requests.get(query_url)\n",
    "  i=Image.open(BytesIO(r.content))\n",
    "  #i = i.convert(\"RGB\")\n",
    "  i.save(\"/content/drive/My Drive/CCAI5/\"+address.replace(\" \",\"\")+\".jpg\")\n",
    "  return(i)\n",
    "\n",
    "\n",
    "#test = GetImage_fromAPI(\"433 rue Forest Mont-Saint-Hilaire QC J3H 4V2\")\n",
    "#plt.imshow(np.array(test))\n",
    "\n",
    "def GetImage_fromDrive(address):\n",
    "  \n",
    "  filename = \"/content/drive/My Drive/CCAI5/\"+address.replace(\" \",\"\")+\".jpg\"\n",
    "  \n",
    "  im = cv2.imread(filename)\n",
    "  return(im)\n",
    "\n",
    "#test = GetImage_fromDrive(\"49.2886395,-123.13281465\")\n",
    "#print(type(test))\n",
    "#plt.imshow(test)\n",
    "#test.max()\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "-OvM83PsSMZM",
    "outputId": "8e9e9808-53e9-49a6-8942-502b3e58dece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[678 678 678 ... 678 678 678]\n",
      " [678 678 678 ... 678 678 678]\n",
      " [678 678 678 ... 678 678 678]\n",
      " ...\n",
      " [678 678 678 ... 678 678 678]\n",
      " [678 678 678 ... 678 678 678]\n",
      " [678 678 678 ... 678 678 678]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## Testing ez filtering tool for empty image\n",
    "np_img = np.array(test)\n",
    "np_sum = np_img.sum(axis=-1)\n",
    "print(np_sum[:10])\n",
    "print(np.all(np_sum[:10]==678))\n",
    "print(\"Fuck yeah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1jCrj5QMjyII",
    "outputId": "e0f26129-be74-4cff-e132-99ada640ae81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "dlA9flgjs-m5",
    "outputId": "5747da6c-348a-415e-c704-b662fad8a544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
      "9412608/9406464 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#Downloading pre-trained model\n",
    "\n",
    "import tensorflow as tf\n",
    "IMG_SHAPE = (128, 128, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model Resnet-50 or VGG19\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hFMAqB3KUqY"
   },
   "outputs": [],
   "source": [
    "### Generator to process data from query\n",
    "import logging\n",
    "\n",
    "def data_generator(dataset, batch_size=50,FromAPI=True):\n",
    "    \"\"\"A generator that returns images and corresponding target class ids,\n",
    "    \"\"\"\n",
    "    b = 0  # batch item index\n",
    "    image_index = -1\n",
    "    error_count = 0\n",
    "    dataset_size = len(dataset)\n",
    "\n",
    "    # Keras requires a generator to run indefinitely.\n",
    "    while True:\n",
    "        try:\n",
    "            # Increment index to pick next image. Shuffle if at the start of an epoch.\n",
    "            image_index = (image_index + 1) % dataset_size\n",
    "\n",
    "            # Targets\n",
    "            numb_floors = dataset.LEVELS[image_index]\n",
    "\n",
    "            # image input\n",
    "            coord = str(dataset.LON[image_index])+\",\" + str(dataset.LAT[image_index])\n",
    "            if FromAPI:\n",
    "              img = np.array(GetImage_fromAPI(coord))\n",
    "            else:\n",
    "              img = GetImage_fromDrive(coord)\n",
    "              #if type(img)!='numpy.ndarray':\n",
    "                #continue\n",
    "            \n",
    "            #Skip images that have no instances. Google query will return it as metadate (no img found)\n",
    "            if img is None:  #if unfindable: download\n",
    "              img = np.array(GetImage_fromAPI(coord))\n",
    "              #continue\n",
    "              \n",
    "            np_sum = img.sum(axis=-1)\n",
    "            if np.all(np_sum[:10]==678):\n",
    "              continue\n",
    "\n",
    "            # Init batch arrays\n",
    "            if b == 0:\n",
    "                \n",
    "                batch_images = np.zeros(\n",
    "                    (batch_size,) + img.shape, dtype=np.float32)\n",
    "                batch_target_class = np.zeros(\n",
    "                    batch_size, dtype=np.int32)\n",
    "\n",
    "            # Add to batch\n",
    "            batch_images[b] = img/255\n",
    "            batch_target_class[b] = numb_floors\n",
    "            b += 1\n",
    "\n",
    "            # Batch full?\n",
    "            if b >= batch_size:\n",
    "                inputs = [batch_images]\n",
    "                outputs = [batch_target_class]\n",
    "\n",
    "                yield inputs, outputs\n",
    "\n",
    "                # start a new batch\n",
    "                b = 0\n",
    "        except (GeneratorExit, KeyboardInterrupt):\n",
    "            raise\n",
    "        except:\n",
    "            # Log it and skip the image\n",
    "            logging.exception(\"Error processing image {}\".format(\n",
    "                dataset.image_info[image_id]))\n",
    "            error_count += 1\n",
    "            if error_count > 5:\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "in5dS43a19Go",
    "outputId": "97505a20-e7ed-4b2d-98fb-00233965a6f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_128 (Model) (None, 4, 4, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 11)                14091     \n",
      "=================================================================\n",
      "Total params: 2,272,075\n",
      "Trainable params: 14,091\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Preparing pre-trained model for fine-tuning\n",
    "import keras\n",
    "base_model.trainable = False\n",
    "#base_model.summary()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(11, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "aFDD-lY0mPU3",
    "outputId": "b57c9d62-e073-42f9-8a95-69f665090bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#Reload model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "model = tf.keras.models.load_model('/content/drive/My Drive/MobileNet_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYnyxClcdScH"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4,clipnorm=1.),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "ASYEJ3lEVP7A",
    "outputId": "f86cb724-e417-4006-e52f-df7e42429c7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>LEVELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-80.967173</td>\n",
       "      <td>35.305898</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-80.938653</td>\n",
       "      <td>35.309034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-80.938848</td>\n",
       "      <td>35.309204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-80.938531</td>\n",
       "      <td>35.308724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-80.936607</td>\n",
       "      <td>35.303380</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LAT        LON  LEVELS\n",
       "0 -80.967173  35.305898       2\n",
       "1 -80.938653  35.309034       1\n",
       "2 -80.938848  35.309204       1\n",
       "3 -80.938531  35.308724       1\n",
       "4 -80.936607  35.303380       1"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.9560513,-75.16571175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22411"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"output-final.csv\",sep=\";\",usecols=[0, 1, 2])\n",
    "display(dataset.head())\n",
    "dataset.LEVELS = dataset.LEVELS.astype(int)\n",
    "#shuffle\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "print(str(dataset.LON[0])+\",\" + str(dataset.LAT[0]))\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "G6szG8rEDjVg",
    "outputId": "f80e09f6-60fc-498a-8920-b924ef641d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "17/16 [===============================] - 752s 44s/step - loss: 2.3121 - acc: 0.1800 - val_loss: 2.3861 - val_acc: 0.2667\n",
      "Epoch 2/5\n",
      "17/16 [===============================] - 836s 49s/step - loss: 1.9813 - acc: 0.3165 - val_loss: 1.8667 - val_acc: 0.3333\n",
      "Epoch 3/5\n",
      "11/16 [===================>..........] - ETA: 6:13 - loss: 1.8548 - acc: 0.3473"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-57687bbf1a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                    \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                    validation_steps=validation_steps)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 50\n",
    "steps_per_epoch = len(dataset)/(10*batch_size)\n",
    "validation_steps = 1\n",
    "train_generator = data_generator(dataset[:8000], batch_size=batch_size, FromAPI=False)\n",
    "valid_generator = data_generator(dataset[8000:].reset_index(drop=True), batch_size=15, FromAPI=False)\n",
    "\n",
    "history_fine = model.fit_generator(train_generator,\n",
    "                                   steps_per_epoch = steps_per_epoch,\n",
    "                                   epochs=epochs,\n",
    "                                   workers=1,\n",
    "                                   validation_data=valid_generator,\n",
    "                                   validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "321JlKf_kF3t"
   },
   "outputs": [],
   "source": [
    "#model.save('/content/drive/My Drive/MobileNet_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "hvHRBD1EP3JJ",
    "outputId": "de5db384-5ca2-4592-8862-0461c24273c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  87\n",
      "Epoch 1/10\n",
      "45/44 [==============================] - 66s 1s/step - loss: 1.6521 - acc: 0.4258 - val_loss: 2.3754 - val_acc: 0.1333\n",
      "Epoch 2/10\n",
      "45/44 [==============================] - 728s 16s/step - loss: 1.3973 - acc: 0.4982 - val_loss: 2.4548 - val_acc: 0.2000\n",
      "Epoch 3/10\n",
      "45/44 [==============================] - 709s 16s/step - loss: 1.3734 - acc: 0.4929 - val_loss: 1.3623 - val_acc: 0.5333\n",
      "Epoch 4/10\n",
      "45/44 [==============================] - 710s 16s/step - loss: 1.2569 - acc: 0.5222 - val_loss: 2.2065 - val_acc: 0.3333\n",
      "Epoch 5/10\n",
      "45/44 [==============================] - 706s 16s/step - loss: 1.2059 - acc: 0.5413 - val_loss: 0.7690 - val_acc: 0.6000\n",
      "Epoch 6/10\n",
      "45/44 [==============================] - 713s 16s/step - loss: 1.1353 - acc: 0.5644 - val_loss: 1.0804 - val_acc: 0.4667\n",
      "Epoch 7/10\n",
      "45/44 [==============================] - 725s 16s/step - loss: 1.1659 - acc: 0.5476 - val_loss: 1.1238 - val_acc: 0.6000\n",
      "Epoch 8/10\n",
      "35/44 [======================>.......] - ETA: 2:34 - loss: 1.1091 - acc: 0.5629"
     ]
    }
   ],
   "source": [
    "model.layers[0].trainable = True\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(model.layers[0].layers))\n",
    "\n",
    "# Fine tune from this layer onwards\n",
    "fine_tune_at = 0\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in model.layers[0].layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "  \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Retrain with fine-tuning\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "steps_per_epoch = len(dataset)/(10*batch_size)\n",
    "validation_steps = 1\n",
    "train_generator = data_generator(dataset[:22000], batch_size=batch_size, FromAPI=False)\n",
    "valid_generator = data_generator(dataset[22000:].reset_index(drop=True), batch_size=15, FromAPI=False)\n",
    "\n",
    "history_fine = model.fit_generator(train_generator,\n",
    "                                   steps_per_epoch = steps_per_epoch,\n",
    "                                   epochs=epochs,\n",
    "                                   workers=1,\n",
    "                                   validation_data=valid_generator,\n",
    "                                   validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "RGONJhG3nAMP",
    "outputId": "c4cec9e8-e65b-4182-9c0f-c50a8da89492"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/16 [===============================] - 13s 752ms/step - loss: 0.1674 - acc: 0.9882 - val_loss: 0.7838 - val_acc: 0.6667\n",
      "Epoch 2/10\n",
      "17/16 [===============================] - 13s 744ms/step - loss: 0.3231 - acc: 0.9282 - val_loss: 1.0620 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "17/16 [===============================] - 13s 759ms/step - loss: 0.3358 - acc: 0.9424 - val_loss: 1.6683 - val_acc: 0.5333\n",
      "Epoch 4/10\n",
      "17/16 [===============================] - 13s 738ms/step - loss: 0.3568 - acc: 0.9176 - val_loss: 1.6185 - val_acc: 0.4000\n",
      "Epoch 5/10\n",
      "17/16 [===============================] - 13s 748ms/step - loss: 0.2918 - acc: 0.9565 - val_loss: 0.6682 - val_acc: 0.6000\n",
      "Epoch 6/10\n",
      "17/16 [===============================] - 13s 739ms/step - loss: 0.3094 - acc: 0.9529 - val_loss: 1.3210 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "17/16 [===============================] - 13s 757ms/step - loss: 0.2680 - acc: 0.9718 - val_loss: 1.0494 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "17/16 [===============================] - 13s 756ms/step - loss: 0.2939 - acc: 0.9518 - val_loss: 1.2940 - val_acc: 0.5333\n",
      "Epoch 9/10\n",
      "17/16 [===============================] - 12s 717ms/step - loss: 0.2523 - acc: 0.9729 - val_loss: 0.9773 - val_acc: 0.6000\n",
      "Epoch 10/10\n",
      "17/16 [===============================] - 12s 711ms/step - loss: 0.1284 - acc: 0.9871 - val_loss: 0.6589 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "#Retrain with fine-tuning\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "steps_per_epoch = len(dataset)/(10*batch_size)\n",
    "validation_steps = 1\n",
    "train_generator = data_generator(dataset[:8000], batch_size=batch_size, FromAPI=False)\n",
    "valid_generator = data_generator(dataset[8000:].reset_index(drop=True), batch_size=15, FromAPI=False)\n",
    "\n",
    "history_fine = model.fit_generator(train_generator,\n",
    "                                   steps_per_epoch = steps_per_epoch,\n",
    "                                   epochs=epochs,\n",
    "                                   workers=1,\n",
    "                                   validation_data=valid_generator,\n",
    "                                   validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_YcuVT72uD8"
   },
   "outputs": [],
   "source": [
    "#model.save('/content/drive/My Drive/MobileNet2_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYZMXhba3R06"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4xC_VL9e43l0",
    "outputId": "c681a57f-2ca0-4779-da26-f21499631cef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnWqffLL46Wc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CCAI_Hackhathon_streetview.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
